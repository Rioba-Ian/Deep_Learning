{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularization  and Dropout.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3sH9qqyjwfq+BZKz2FFe1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rioba-Ian/Deep_Learning/blob/main/Regularization_and_Dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u9E10BqEOvY"
      },
      "source": [
        "# Regularization \n",
        "\n",
        "Regularization is a technique which involves making slight modifications to the learning algorithm  such that the model generalizes better. This in turn will improve the model's perfromance on the unseen test data set as well. \n",
        "<br>\n",
        "Adding more than required layers adds to overfitting in the model. \n",
        "<br>\n",
        "Regularization isn't a quick concept that needs to be mastered, but rather slowly. \n",
        "<br>\n",
        "We add regularization in the neural network by doing the following\n",
        "> model.add(Dense(256, activation='relu', kernel_regularizer= 'l2'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tToEo7OLFRmz"
      },
      "source": [
        "# Dropouts \n",
        "Dropout is a regularization method approximating training a large number of neural networks with different architechtures in parallel. It is preferred when training a large neural network. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "gYhWnt94B-Nr",
        "outputId": "efc3f71a-b2ad-4e9e-d637-a39eff5a3901"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png',\n",
        "      width = 800, height=500)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png\" width=\"800\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3UnhoeKGIeh"
      },
      "source": [
        "By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GwR-6_QGT01"
      },
      "source": [
        "Dropout has the effect of making the training process, noisy, forcing nodes within a layer to probabilistically take on more or less responsibility for the inputs. This conceptualization suggests that perhaps droupout breaks-up situations where network layers co-adapt to correct mistakes form prior layers, in turn making the model more robust.\n",
        "<br>\n",
        "\n",
        "It can be used with most types of layers, such as dense fully connected layers, convolution layers, and recurrent layers such as the LSTM layer. Dropout may be implemented on any or all hidden layers in the network as well as the visible or input layer. \n",
        "<br>\n",
        "\n",
        "It is not used in the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FNAhE-2Fwce",
        "outputId": "998f3d09-6d3b-4398-a2c8-d1b854f01c5e"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "# import matplotlib \n",
        "import numpy as np \n",
        "import matplotlib \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline \n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "Kr3nJDgIHofJ",
        "outputId": "3b2f2933-127a-4eb8-acbd-cfc1996090d1"
      },
      "source": [
        "images = X_train[:3]\n",
        "labels = y_train[:3]\n",
        "\n",
        "f, ax = plt.subplots(nrows=1, ncols=3, figsize=(20,4))\n",
        "\n",
        "for index,(img, ax) in enumerate(zip(images, ax)):\n",
        "    \n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.axis('off')\n",
        "    ax.text(0.6, -2.0, f\"Digit in the image {labels[index]}\", size=15, ha='center')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HB5AoDVIfgY"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout \n",
        "from tensorflow.keras.optimizers import SGD \n",
        "from tensorflow.keras.callbacks import TensorBoard \n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import regularizers\n",
        "from datetime import datetime"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRH_TKyTJUF2"
      },
      "source": [
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qap_axPiJetS"
      },
      "source": [
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQw8sxWDJm0k"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', input_shape=(784, )))\n",
        "model.add(Dropout(0.2)) #adding dropout\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer='l2')) # using regulaizer\n",
        "model.add(Dropout(0.2)) #adding dropout\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer='l2')) # using regulaizer\n",
        "model.add(Dropout(0.2)) #using dropout\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dugumvjuKh6n"
      },
      "source": [
        "logdir = 'logs/' + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir=logdir)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCDjoJhQK97P",
        "outputId": "180c47b7-2552-4ef5-8e40-7092ee1dbd35"
      },
      "source": [
        "training_history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    verbose=1,\n",
        "    epochs=10,\n",
        "    validation_data = (X_test, y_test),\n",
        "    callbacks=[tensorboard_callback, es],\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 3.5652 - accuracy: 0.2257 - val_loss: 0.8727 - val_accuracy: 0.7149\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1198 - accuracy: 0.6038 - val_loss: 0.6897 - val_accuracy: 0.7700\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9798 - accuracy: 0.6513 - val_loss: 0.6211 - val_accuracy: 0.7848\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8995 - accuracy: 0.6930 - val_loss: 0.6238 - val_accuracy: 0.8196\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8678 - accuracy: 0.7089 - val_loss: 0.6113 - val_accuracy: 0.8543\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8423 - accuracy: 0.7391 - val_loss: 0.5719 - val_accuracy: 0.8549\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8289 - accuracy: 0.7485 - val_loss: 0.5759 - val_accuracy: 0.8551\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8288 - accuracy: 0.7467 - val_loss: 0.5591 - val_accuracy: 0.8620\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.8257 - accuracy: 0.7558 - val_loss: 0.5809 - val_accuracy: 0.8564\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8092 - accuracy: 0.7558 - val_loss: 0.5582 - val_accuracy: 0.8586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f7Eoi15L4xf"
      },
      "source": [
        "In most cases, dropouts is used in deep/wide neural networks. This is a very basic one. The training will require more epochs to train. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-hodymuN1QC"
      },
      "source": [
        "## Why not just use early stopping rather than regularization?\n",
        "The main downside of earlystopping is that this couples two tasks:\n",
        "1. Algorithm to optimize the cost function\n",
        "2. Prevent overfitting\n",
        "<br>\n",
        "\n",
        "because by stopping gradient descent early, we are sort of breaking whatever we are building through optimization in the cost function and simultaneously trying not to over fit. Rather than using early stopping, one alternative is the L2 regularization then we can just train the neural network as long as possible - another drawback would be that we would try out different values for the lamda regularization parameter to obtain a really good one. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQNPk947O2u-"
      },
      "source": [
        "**Points to conclude**\n",
        "* Large weights in a neural network are a sign of a more complex network needed to fit which may lead to overfitting the training data.\n",
        "* Probabilistically dropping out nodes in the network is a simple and effecting regularization method. \n",
        "* A large network with more training and the use of a weight constraint are suggested when using the dropout"
      ]
    }
  ]
}