{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af28372",
   "metadata": {},
   "source": [
    "## fastText Tutorial notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acec1c0",
   "metadata": {},
   "source": [
    "This notebook is a representation of the facebook machine learning library called fastText which is quite awesome in word labelling and representation. The machine learning library can be applied to whatsoever purpose. In this notebook we show how the library can be used in supervised machine learning and even be tuned to be fast and more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112f59c8",
   "metadata": {},
   "source": [
    "The tools used are a command line terminal; PS: Linux is recommended for the terminal, I have used the zsh terminal along side this notebook. Some of the zsh terminal commands might not really work in the notebook and thus I shifted to the zsh or any terminal you would prefer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade6fbff",
   "metadata": {},
   "source": [
    "!wget https://github.com/facebookresearch/fastText/archive/v0.9.2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef3e33d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 308 kB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pybind11>=2.2\n",
      "  Using cached pybind11-2.8.0-py2.py3-none-any.whl (207 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/lib/python3.9/site-packages (from fasttext) (57.4.0)\n",
      "Requirement already satisfied: numpy in /home/rioba/.local/lib/python3.9/site-packages (from fasttext) (1.21.2)\n",
      "Using legacy 'setup.py install' for fasttext, since package 'wheel' is not installed.\n",
      "Installing collected packages: pybind11, fasttext\n",
      "    Running setup.py install for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fasttext-0.9.2 pybind11-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ecf86ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd8f1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module fasttext.FastText in fasttext:\n",
      "\n",
      "NAME\n",
      "    fasttext.FastText\n",
      "\n",
      "DESCRIPTION\n",
      "    # Copyright (c) 2017-present, Facebook, Inc.\n",
      "    # All rights reserved.\n",
      "    #\n",
      "    # This source code is licensed under the MIT license found in the\n",
      "    # LICENSE file in the root directory of this source tree.\n",
      "\n",
      "FUNCTIONS\n",
      "    cbow(*kargs, **kwargs)\n",
      "    \n",
      "    eprint(*args, **kwargs)\n",
      "    \n",
      "    load_model(path)\n",
      "        Load a model given a filepath and return a model object.\n",
      "    \n",
      "    read_args(arg_list, arg_dict, arg_names, default_values)\n",
      "    \n",
      "    skipgram(*kargs, **kwargs)\n",
      "    \n",
      "    supervised(*kargs, **kwargs)\n",
      "    \n",
      "    tokenize(text)\n",
      "        Given a string of text, tokenize it and return a list of tokens\n",
      "    \n",
      "    train_supervised(*kargs, **kwargs)\n",
      "        Train a supervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input file must must contain at least one label per line. For an\n",
      "        example consult the example datasets which are part of the fastText\n",
      "        repository such as the dataset pulled by classification-example.sh.\n",
      "    \n",
      "    train_unsupervised(*kargs, **kwargs)\n",
      "        Train an unsupervised model and return a model object.\n",
      "        \n",
      "        input must be a filepath. The input text does not need to be tokenized\n",
      "        as per the tokenize function, but it must be preprocessed and encoded\n",
      "        as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "        as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "        \n",
      "        The input field must not contain any labels or use the specified label prefix\n",
      "        unless it is ok for those words to be ignored. For an example consult the\n",
      "        dataset pulled by the example script word-vector-example.sh, which is\n",
      "        part of the fastText repository.\n",
      "\n",
      "DATA\n",
      "    BOW = '<'\n",
      "    EOS = '</s>'\n",
      "    EOW = '>'\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    displayed_errors = {}\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 1310...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    unicode_literals = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', ...\n",
      "    unsupervised_default = {'autotuneDuration': 300, 'autotuneMetric': 'f1...\n",
      "\n",
      "FILE\n",
      "    /home/rioba/.local/lib/python3.9/site-packages/fasttext/FastText.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "help(fasttext.FastText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1c2f43",
   "metadata": {},
   "source": [
    "train_supervised() will mostly be used for retruning a model object and calling test and predict on that object. This is the same as learning the text classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6a6ed",
   "metadata": {},
   "source": [
    "## Getting the data and preparing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e04a96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-06 15:53:24--  https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz\n",
      "SSL_INIT\n",
      "Loaded CA certificate '/etc/ssl/certs/ca-certificates.crt'\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 457609 (447K) [application/x-tar]\n",
      "Saving to: ‘cooking.stackexchange.tar.gz’\n",
      "\n",
      "cooking.stackexchan 100%[===================>] 446.88K   260KB/s    in 1.7s    \n",
      "\n",
      "2021-10-06 15:53:27 (260 KB/s) - ‘cooking.stackexchange.tar.gz’ saved [457609/457609]\n",
      "\n",
      "cooking.stackexchange.id\n",
      "cooking.stackexchange.txt\n",
      "readme.txt\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/data/cooking.stackexchange.tar.gz && tar xvzf cooking.stackexchange.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c1d1508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  14543\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   75204 lr:  0.000000 avg.loss: 10.067896 ETA:   0h 0m 0s 0s\n"
     ]
    }
   ],
   "source": [
    "model = fasttext.train_supervised(input=\"cooking.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cc3ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"model_cooking.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79028bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__baking',), array([0.08457895]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Which baking dish is best to bake a taco?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d25ef97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__baking',), array([0.02988265]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"What do we call the process of submerging veggies or fruits quickly in boiling water?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d46e0b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.11766666666666667, 0.05088655038200952)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d128ee",
   "metadata": {},
   "source": [
    "The precision is 0.117667 and the recall is at 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a679fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.0672, 0.14530776992936428)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"cooking.valid\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b88fe4",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add6ac8",
   "metadata": {},
   "source": [
    "Precision is the number of correct ones among the predicted ones. Recall is the number of labels that were predicted among the real labels. We shall use an example; \n",
    "<br>\n",
    "<em>Why not put knives in the dishwasher</em>\n",
    "<br>\n",
    "On the stack exchange this is labelled with three tags: <code>equipment, cleaning and knives</code>, and these can be predicted by these labels:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91653607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__baking',\n",
       "  '__label__food-safety',\n",
       "  '__label__bread',\n",
       "  '__label__substitutions',\n",
       "  '__label__equipment'),\n",
       " array([0.08093037, 0.06498709, 0.03857679, 0.03446391, 0.03077549]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\"Why not put knives in the dishwasher?\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e32781",
   "metadata": {},
   "source": [
    "The labels we have got are <code> baking, food-safety, bread, substitutions and equipment</code>. Thus there are 2 out of 5 labels predicted correctly. This means that the precision is 0.40. Out of the three labels, only 2 have been predicted correctly, meaning the recall is 0.6667."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635afaa6",
   "metadata": {},
   "source": [
    "## So How Do we make the model better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5853a",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2571bb",
   "metadata": {},
   "source": [
    "We could first remove the uppercase and punctuation marks. A crude normalization ccan be obtained using the command line tools such as <code>sed and tr</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dd0f4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   81834 lr:  0.000000 avg.loss:  9.896623 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_preprocssed = fasttext.train_supervised(input=\"cooking.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f94d2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.11933333333333333, 0.05160732305030993)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7a501",
   "metadata": {},
   "source": [
    "The precision has gone up, now let us try increasing the epochs and lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcc8b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   79863 lr:  0.000000 avg.loss:  5.073856 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_hyperparameter_tuned_epochs = fasttext.train_supervised(input=\"cooking.train\", epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3658af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.5656666666666667, 0.2446302436211619)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_epochs.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04df68ab",
   "metadata": {},
   "source": [
    "Quite strong!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "774cb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   81884 lr:  0.000000 avg.loss:  6.625004 ETA:   0h 0m 0s100.0% words/sec/thread:   81886 lr: -0.000060 avg.loss:  6.625004 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr = fasttext.train_supervised(input=\"cooking.train\", lr=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a636d125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.562, 0.24304454375090095)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned_lr.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43e8b6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   72156 lr:  0.000000 avg.loss:  4.688759 ETA:   0h 0m 0s words/sec/thread:   72156 lr: -0.000011 avg.loss:  4.688759 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_hyperparameter_tuned = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b138655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.5893333333333334, 0.2548652155110278)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameter_tuned.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88abeb",
   "metadata": {},
   "source": [
    "### using word n-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868b6358",
   "metadata": {},
   "source": [
    "Using bigrams instead of unigrams greatly improves a model. This is useful in sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cde4a5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:   78878 lr:  0.000000 avg.loss:  3.073013 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_bigrams = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25, wordNgrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38401950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.599, 0.2590456969871702)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bigrams.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a98c478",
   "metadata": {},
   "source": [
    "Right now the precision has gone to 59.9%, due to the following:-\n",
    "<br>\n",
    "<ul>\n",
    "    <li> preprocessing data </li>\n",
    "    <li> changing the epochs between 5-50 </li>\n",
    "    <li> changing the learning rate 0.1 - 10 </li>\n",
    "    <li> using word n-grams; a range or 1 to 5 </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c028f434",
   "metadata": {},
   "source": [
    "## Hierarchical softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2407e6f1",
   "metadata": {},
   "source": [
    "A potential solution for faster training is to use hierarchical softmax instead of the regular softmax. This can be utilised with the option <code>-loss hs </code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ec5d258",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread: 1475070 lr:  0.000000 avg.loss:  2.269904 ETA:   0h 0m 0s% words/sec/thread: 1475158 lr: -0.000003 avg.loss:  2.269904 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "model_hsoftmax = fasttext.train_supervised(input=\"cooking.train\", lr=1.0, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='hs') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02321164",
   "metadata": {},
   "source": [
    "This has been sooo fast!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c08c8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.585, 0.25299120657344676)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hsoftmax.test(\"cooking.valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dc9a8",
   "metadata": {},
   "source": [
    "The hierarchical softmax is a loss function that apprpximates the softmax with a much faster computation. It does this by using a binary tree that has leaves corresponding to the labels. Each intermediate node has a binary decsion activation ~ sigmoid that is trained and predicts if we should go to the left or right. The probability of output is given by the product of the probabilities of the intermediate nodes along the path from the roor to the output unit leaf. In fastText, we use a Huffman tree so that the lookup time is faster for ore frequent outputs and thus the avergae lookuptime for the output is optimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8483085",
   "metadata": {},
   "source": [
    "### Multi-label classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105718e",
   "metadata": {},
   "source": [
    "When we would like to assign a document to multiple labels, we can still softmax loss and play with hyperparameter tuning for prediction. Playing with these argumnets can be unintuitive becuase teh proablities need to sum up to 1.A better way is to handle multiple labels and use independent binary classifiers for each label bu using <code> -loss one-vs-all or -loss ova </code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3619438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  8952\n",
      "Number of labels: 735\n",
      "Progress: 100.0% words/sec/thread:  128578 lr:  0.000000 avg.loss:  4.948205 ETA:   0h 0m 0s 36.9% words/sec/thread:  121484 lr:  0.315417 avg.loss: 12.150004 ETA:   0h 0m 7s\n"
     ]
    }
   ],
   "source": [
    "model_multi= fasttext.train_supervised(input=\"cooking.train\", lr=0.5, epoch=25, wordNgrams=2, bucket=200000, dim=50, loss='ova')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac9c31",
   "metadata": {},
   "source": [
    "The predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b761eb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('__label__baking',\n",
       "  '__label__equipment',\n",
       "  '__label__bread',\n",
       "  '__label__bananas'),\n",
       " array([1.00001001, 0.9994216 , 0.99288857, 0.97772384]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi.predict(\"Which baking dish is the best to bake a banana bread ?\", k=-1, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5692ee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 0.003146031746031746, 1.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_multi.test(\"cooking.valid\", k=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7528c1",
   "metadata": {},
   "source": [
    "Wow, a recall of 1.0!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python397jvsc74a57bd0e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
